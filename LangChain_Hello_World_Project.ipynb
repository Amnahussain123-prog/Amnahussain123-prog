{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMD6JSLiAHJLyqkOIydvfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amnahussain123-prog/Amnahussain123-prog/blob/main/LangChain_Hello_World_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "pujMcHTP6Ucy"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9rTL9VXt6lxl",
        "outputId": "f18bb766-9ef2-442a-bbc8-16ce3530487f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyBV_ev9klik5WKlMgkeqhYvf6V4CB9jZyU'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq google-genAI"
      ],
      "metadata": {
        "id": "xVpGyMmd7pEs"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain_community"
      ],
      "metadata": {
        "id": "iriKHsA39Kgc"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq --upgrade google-generativeai"
      ],
      "metadata": {
        "id": "vYs4KhqZ9ebq"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain_google_genai"
      ],
      "metadata": {
        "id": "qQz-bg3Fnj8O"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "Wa3CJvLcDekr"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from langchain_community import llms\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import google_palm"
      ],
      "metadata": {
        "id": "T0PW-g1t7xZP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm : ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    api_key = userdata.get('GOOGLE_API_KEY'),\n",
        "    model = 'gemini-1.5-flash',\n",
        "    temperature=0.9\n",
        ")"
      ],
      "metadata": {
        "id": "YIkSUhT590-0"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['question'],\n",
        "    input_types={'question': str},\n",
        "    partial_variables={'format': 'json'},\n",
        "    template=\"You are a helpful assistant. Answer the following question:\\n\\n{question}\"\n",
        ")"
      ],
      "metadata": {
        "id": "FyqOiicw-yy2"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=LLMChain(verbose= True, llm=llm, prompt=prompt_template)\n",
        "question=\"what is langchain?, Discuss its importance in making agents?\"\n",
        "try:\n",
        "    response = chain.run({'question': question})\n",
        "    print(\"Answer:\", response)\n",
        "    print(\"Type:\", type(response))\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "question=\"what is langgraph?\"\n",
        "try:\n",
        "    response = chain.run({'question': question})\n",
        "    print(\"Answer:\", response)\n",
        "    print(\"Type:\", type(response))\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1DUl_XtEhSG",
        "outputId": "1ce624fc-01e8-4116-e8bd-1ad7c5a37e8c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a helpful assistant. Answer the following question:\n",
            "\n",
            "what is langchain?, Discuss its importance in making agents?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Answer: LangChain is a framework for developing applications powered by large language models (LLMs).  It's not an LLM itself, but rather a collection of tools and components designed to make it easier to build applications that leverage the capabilities of LLMs effectively.  Think of it as a toolbox specifically designed for LLM-based development.\n",
            "\n",
            "LangChain's key features that make it crucial for building agents include:\n",
            "\n",
            "* **Modular Components:** LangChain offers modular components that handle various aspects of LLM application development, including:\n",
            "    * **Models:**  Integration with various LLMs (OpenAI, Hugging Face, etc.), allowing you to easily swap models based on your needs and budget.\n",
            "    * **Prompts:** Tools for constructing and managing prompts, optimizing their effectiveness, and experimenting with different prompt engineering techniques.\n",
            "    * **Indexes:**  Methods for connecting LLMs to external data sources (documents, databases, etc.), enabling them to access and process information beyond their training data.  This is extremely important for agents that need to interact with the real world.\n",
            "    * **Chains:**  Mechanisms for combining multiple components (LLMs, prompts, indexes) into workflows, creating sophisticated sequences of operations. This allows agents to perform complex tasks requiring multiple steps.\n",
            "    * **Agents:**  This is where LangChain truly shines in agent development. It provides the infrastructure for building autonomous agents that can choose which tools to use and when, based on the given task.  This is a significant step beyond simply prompting an LLM; agents can actively decide how to solve a problem.\n",
            "    * **Memory:**  Capabilities for LLMs to \"remember\" previous interactions within a conversation or task, enhancing context and improving performance over time. This is essential for agents to maintain state and understand the history of their interactions.\n",
            "\n",
            "\n",
            "* **Ease of Use:** LangChain simplifies the process of integrating LLMs into applications by abstracting away much of the underlying complexity.  This allows developers to focus on the application logic rather than the intricate details of LLM interaction.\n",
            "\n",
            "* **Extensibility:** LangChain is designed to be extensible, allowing developers to easily integrate custom components and adapt it to their specific needs.  This is vital for creating agents that are tailored to particular domains or tasks.\n",
            "\n",
            "\n",
            "**Importance in Making Agents:**\n",
            "\n",
            "LangChain's importance in building agents stems from its ability to handle the complexities of agent design.  Traditional LLM applications often involve simple prompt-response interactions.  Agents, however, require more advanced capabilities:\n",
            "\n",
            "* **Tool Selection:** Agents need to decide which tools (e.g., search engines, calculators, databases) are relevant to a given task. LangChain's agent components facilitate this decision-making process.\n",
            "\n",
            "* **Planning and Reasoning:** Agents often need to break down complex tasks into smaller subtasks and execute them sequentially. LangChain's chains and memory functionalities support this planning and reasoning.\n",
            "\n",
            "* **External Knowledge Access:**  Agents frequently require access to external information sources. LangChain's indexing capabilities enable agents to connect to and process data from various sources.\n",
            "\n",
            "* **Autonomous Operation:** LangChain enables the creation of truly autonomous agents that can operate without constant human intervention.\n",
            "\n",
            "\n",
            "In short, LangChain provides a comprehensive and user-friendly framework for building sophisticated LLMs-powered agents that can interact with their environment, access external information, and perform complex tasks autonomously.  It streamlines the development process, making it easier to create powerful and adaptable agents.\n",
            "\n",
            "Type: <class 'str'>\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a helpful assistant. Answer the following question:\n",
            "\n",
            "what is langgraph?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Answer: LangGraph is a knowledge graph specifically designed for natural language processing (NLP).  Instead of representing general knowledge, it focuses on linguistic information, relationships between words and phrases, and grammatical structures.  This makes it useful for tasks like:\n",
            "\n",
            "* **Word sense disambiguation:** Determining the correct meaning of a word in context.\n",
            "* **Semantic parsing:** Converting natural language into a formal representation.\n",
            "* **Question answering:** Finding answers to questions posed in natural language.\n",
            "* **Machine translation:** Translating text from one language to another.\n",
            "* **Text summarization:** Condensing large amounts of text into shorter summaries.\n",
            "\n",
            "Essentially, LangGraph provides a structured representation of language that allows NLP models to better understand and reason about text.  It's a tool that helps bridge the gap between unstructured natural language and the structured data that machines prefer.  While there isn't one single, universally recognized \"LangGraph\" project, the concept describes a type of knowledge graph used in many NLP applications.\n",
            "\n",
            "Type: <class 'str'>\n"
          ]
        }
      ]
    }
  ]
}